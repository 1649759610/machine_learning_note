# 激活函数

### **激活函数**

**激活函数**是添加到神经网络中的一种函数，它的引入能够使得网络获得非线性的信息处理能力。因此激活函数本身肯定不是一种线性函数，要不然怎么指望它"掰弯"这些网络中的线性数据呢。

![](../../.gitbook/assets/image%20%281%29.png)

### 激活函数是怎么发挥光热的

不妨将时间轴拉得远一点，从最开始的神经元来这里，来看看激活函数是怎么发挥作用的。

怎么理解"掰弯"这些线性数据呢，我们将时间轴拉得远一点，从最开始的人工神经元的计算方式开始扯起，下边这个图展示了人工神经元处理数据，进行计算的方式：

![](../../.gitbook/assets/image%20%283%29.png)

神经元的计算方式很简单，首先将输入数据进行线性变换：加权求和加偏置，然后将线性变换结果传入一个曲线函数，将原来的线性数据"掰弯"，从而获得非线性结果。这里的这个曲线函数就是本节的话题眼-激活函数。

### **为什么要将数据进行"掰弯"呢？**

我们知道，模型学习本质上其实是从训练数据中匹配数据的模式，拟合数据中存在的规律。但是这些模式或者规律往往可能很复杂，线性变换完全搞不定，训练效果会很"辣眼睛"，这个时候，我们希望不要把眼光局限在线性变换里面，我们还有非线性变换这份更广阔的天地。

**因此，**在线性变换结果的后边加上了激活函数将数据"掰弯"，获得非线性的输出结果，这会使模型具有更好的拟合训练数据的能力。

**举个例子了解一下**，我们来看下图，图中有两类点，红色的点是一类，绿色的点是一类。现在我们希望找到一条线将这两类点比较好的分割开。

如果我们非得使用线性直线进行分割，那结果就像左边这个图显示的这样，使用线性线段不论你怎么分割，都没有办法将两类数据点完全分隔开。

那如果我们使用曲线来分割这两类点的话，就像右边这个图显示的这样，还是比较容易找出一条曲线来将这两类点分割开的。

**这也就比较感性地表明**，相比直线，曲线的拟合能力更强，非线性变换的拟合能力更强，添加激活函数将线性变换结果"掰弯"后的模型拟合能力更强。

![](../../.gitbook/assets/image%20%284%29.png)







